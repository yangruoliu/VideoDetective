<!doctype html>
<html lang="en">

<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>VideoDetective: Clue Hunting for Long Video Understanding</title>
  <meta name="description"
    content="VideoDetective: Clue Hunting via both Extrinsic Query and Intrinsic Relevance for Long Video Understanding." />
  <link rel="stylesheet" href="./assets/styles.css?v=2.5" />
  <style>
    /* Inline fallback for Dropdown to ensure it works immediately */
    .dropdown {
      position: relative;
      display: inline-block;
    }

    .dropdown-content {
      display: none;
      position: absolute;
      right: 0;
      background-color: #ffffff;
      min-width: 160px;
      box-shadow: 0px 8px 16px 0px rgba(0, 0, 0, 0.2);
      z-index: 100;
      border-radius: 8px;
      padding: 5px 0;
      border: 1px solid #eee;
    }

    .dropdown-content a {
      color: #333;
      padding: 10px 16px;
      text-decoration: none;
      display: block;
      font-size: 0.9rem;
      text-align: left;
    }

    .dropdown-content a:hover {
      background-color: #f1f1f1;
      color: #4a90e2;
    }

    .dropdown:hover .dropdown-content {
      display: block;
    }

    .dropdown-toggle {
      cursor: pointer;
    }
  </style>
  <!-- Optional: Add Google Fonts for better typography -->
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Roboto:wght@300;400;500;700&display=swap" rel="stylesheet">
</head>

<body>

  <div class="container">
    <!-- Top Navigation -->
    <nav class="top-nav">
      <div class="dropdown">
        <button class="more-research-btn dropdown-toggle">
          <span>More Research</span>
          <svg width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"
            stroke-linecap="round" stroke-linejoin="round">
            <polyline points="6 9 12 15 18 9"></polyline>
          </svg>
        </button>
        <div class="dropdown-content">
          <a href="https://video-mme.github.io/home_page.html" target="_blank">Video-MME</a>
          <a href="https://github.com/BradyFU/Awesome-Multimodal-Large-Language-Models" target="_blank">Awesome-MLLM</a>
        </div>
      </div>
    </nav>

    <!-- Hero Section -->
    <header class="hero-header">
      <h1 class="paper-title">
        <div class="title-row">
          <span class="title-main">VideoDetective</span>
          <span class="title-icon">üïµÔ∏è</span>
        </div>
        <span class="title-sub">Clue Hunting via both Extrinsic Query and Intrinsic Relevance for Long Video
          Understanding</span>
      </h1>

      <div class="authors-list">
        <span class="author-name">Ruoliu Yang<sup>1</sup>,</span>
        <span class="author-name">Chu Wu<sup>1</sup>,</span>
        <span class="author-name">Caifeng Shan<sup>1</sup>,</span>
        <span class="author-name">Ran He<sup>2</sup>,</span>
        <span class="author-name">Chaoyou Fu<sup>1</sup></span>
      </div>

      <div class="institutions-list">
        <span class="institution-name"><sup>1</sup>Nanjing University</span>
        <span class="institution-name"><sup>2</sup>Institute of Automation, Chinese Academy of Sciences</span>
      </div>

      <div class="link-buttons">
        <!-- ArXiv Link -->
        <a href="#" class="btn-link">
          <span class="btn-icon">üìÑ</span> ArXiv
        </a>

        <!-- Code Link -->
        <a href="https://github.com/yangruoliu/VideoDetective" class="btn-link">
          <span class="btn-icon">üíª</span> Code
        </a>
      </div>
    </header>

    <!-- Abstract / Overview -->
    <section id="overview">
      <div class="abstract-box">
        <h2 style="margin-top:0;">Abstract</h2>
        <p class="abstract-text">
          Long video understanding remains challenging for multimodal large language models (MLLMs) due to limited
          context windows, which necessitate identifying sparse query-relevant video segments. However, existing methods
          predominantly localize clues based solely on the query, overlooking the video‚Äôs intrinsic structure and
          varying relevance across segments.
        </p>
        <p class="abstract-text">
          <strong>VideoDetective</strong> integrates <strong>extrinsic query relevance</strong> with <strong>intrinsic
            inter-segment affinity</strong> for effective clue hunting. It models the video as a visual‚Äìtemporal
          affinity graph and performs a Hypothesis‚ÄìVerification‚ÄìRefinement loop to obtain a global relevance
          distribution from sparse observations.
        </p>
      </div>

      <h3>Key Ideas</h3>
      <ul class="key-ideas-list">
        <li>
          <strong>Combine Extrinsic query and Intrinsic Relevance:</strong> Understanding long video driven by not only
          extrinsic query but also the video's intrinsic structure,
          achieve "See Less but Know More".
        </li>
        <li>
          <strong>Visual‚ÄìTemporal Affinity Graph:</strong> Built from visual similarity and temporal proximity to model
          video structure and quantify the similarity between video segments.
        </li>
        <li>
          <strong>Hypothesis‚ÄìVerification‚ÄìRefinement Loop:</strong> Estimates relevance scores and propagates them to
          unseen segments, enabling global understanding from sparse observations.
        </li>
      </ul>
    </section>

    <!-- Framework -->
    <section id="framework">
      <h2>Framework</h2>
      <div class="figure-container">
        <img src="./images/figure1_final_final.png" alt="VideoDetective Framework" class="figure-img" />
        <p class="figure-caption">Figure 1. Overview of the VideoDetective framework.</p>
      </div>
    </section>

    <!-- Results -->
    <section id="results">
      <h2>Results</h2>
      <div class="figure-container">
        <img src="./images/figure2_VideoDetective.png" alt="VideoDetective Results" class="figure-img" />
        <p class="figure-caption">Figure 2. Performance improvements brought by VideoDetective.</p>
      </div>
    </section>

    <!-- Example (Placeholder) -->
    <section id="example">
      <h2>Example</h2>
      <div class="figure-container">
        <img src="./images/example_white.png" alt="VideoDetective Example" class="figure-img" />
        <p class="figure-caption">Figure 3. Example of VideoDetective.</p>
      </div>
    </section>

    <!-- Quick Start (Simplified) -->
    <section id="quickstart">
      <h2>Quick Start</h2>
      <p>You can quickly test VideoDetective using our provided scripts.</p>



      <h3>Run Demo</h3>
      <pre><code>python scripts/test_run.py \
  --video_path /path/to/video.mp4 \
  --question "What is the man doing?" \
  --options "A. Running, B. Walking, C. Sitting, D. Standing" \
  --output_dir output \
  --max_steps 10 \
  --total_budget 32</code></pre>
    </section>

    <!-- Citation -->
    <section id="citation">
      <h2>Citation</h2>
      <div class="citation-block">
        <pre><code>@misc{yang2026videodetective,
  title  = {VideoDetective: Clue Hunting via both Extrinsic Query and Intrinsic Relevance for Long Video Understanding},
  author = {Yang, Ruoliu and Wu, Chu and Shan, Caifeng and He, Ran and Fu, Chaoyou},
  year   = {2026}
}</code></pre>
      </div>
    </section>

    <!-- Footer -->
    <footer class="page-footer">
      <p>
        ¬© 2026 VideoDetective. Hosted on GitHub Pages. <br>
        <a href="#">Back to Top</a>
      </p>
    </footer>

  </div>

</body>

</html>